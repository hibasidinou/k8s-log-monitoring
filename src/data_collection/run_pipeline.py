# src/data_collection/run_pipeline.py
import sys
from pathlib import Path

def run_pipeline():
    """ExÃ©cute tout le pipeline de collecte de donnÃ©es"""
    
    print("=" * 60)
    print("ğŸš€ PIPELINE COMPLET DE COLLECTE DE DONNÃ‰ES K8S")
    print("=" * 60)
    
    # 1. TÃ©lÃ©chargement des datasets Kaggle
    print("\n1. ğŸ“¥ TÃ‰LÃ‰CHARGEMENT DES DATASETS KAGGLE")
    print("-" * 40)
    
    try:
        from download_dataset import main as download_main
        if not download_main():
            print("âŒ Ã‰chec du tÃ©lÃ©chargement")
            return False
    except ImportError as e:
        print(f"âŒ Impossible d'importer download_dataset: {e}")
        return False
    
    # 2. GÃ©nÃ©ration de logs simulÃ©s
    print("\n\n2. ğŸ­ GÃ‰NÃ‰RATION DE LOGS SIMULÃ‰S")
    print("-" * 40)
    
    try:
        from generate_simulated_logs import main as generate_main
        generate_main()
    except ImportError as e:
        print(f"âš ï¸  Impossible de gÃ©nÃ©rer les logs simulÃ©s: {e}")
        print("   Continuation sans logs simulÃ©s...")
    
    # 3. CrÃ©ation du dataset hybride (supposÃ© dÃ©jÃ  fait)
    print("\n\n3. ğŸ”— CRÃ‰ATION DU DATASET HYBRIDE")
    print("-" * 40)
    
    hybrid_path = Path("data/processed/hybrid_security_system_dataset.csv")
    if hybrid_path.exists():
        print(f"âœ… Dataset hybride dÃ©jÃ  crÃ©Ã©: {hybrid_path}")
        print(f"   Taille: {hybrid_path.stat().st_size / (1024*1024):.2f} MB")
    else:
        print("âš ï¸  Dataset hybride non trouvÃ©")
        print("   ExÃ©cution de create_hybrid_dataset.py...")
        try:
            from create_hybrid_dataset import create_hybrid_dataset
            create_hybrid_dataset()
        except ImportError as e:
            print(f"âŒ Impossible de crÃ©er le dataset hybride: {e}")
            return False
    
    # 4. Validation des donnÃ©es
    print("\n\n4. ğŸ” VALIDATION DES DONNÃ‰ES")
    print("-" * 40)
    
    try:
        from data_validator import main as validate_main
        validate_main()
    except ImportError as e:
        print(f"âš ï¸  Impossible de valider les donnÃ©es: {e}")
    
    # RÃ©sumÃ© final
    print("\n" + "=" * 60)
    print("ğŸ‰ PIPELINE DE COLLECTE TERMINÃ‰ AVEC SUCCÃˆS!")
    print("=" * 60)
    
    # Lister les fichiers produits
    print("\nğŸ“ FICHIERS PRODUITS:")
    
    data_dir = Path("data")
    for item in sorted(data_dir.rglob("*")):
        if item.is_file() and item.suffix in ['.csv', '.parquet', '.json']:
            size_mb = item.stat().st_size / (1024*1024)
            rel_path = item.relative_to(data_dir.parent)
            print(f"   ğŸ“„ {rel_path} ({size_mb:.2f} MB)")
    
  
    print("\n PrÃªt Ã  passer Ã  Spark!")

if __name__ == "__main__":
    run_pipeline() 